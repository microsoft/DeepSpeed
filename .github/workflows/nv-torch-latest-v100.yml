name: nv-torch-latest-v100

on:
  workflow_dispatch:
  pull_request:
    paths-ignore:
      - 'docs/**'
      - 'blogs/**'
      - 'deepspeed/inference/v2/**'
      - 'tests/unit/inference/v2/**'
  merge_group:
    branches: [ master ]
  schedule:
    - cron: "0 0 * * *"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit-tests:
    runs-on: [self-hosted, nvidia, cu121, v100] # Modified to run on the test runner

    steps:
      - uses: actions/checkout@v4

      - id: setup-venv
        uses: ./.github/workflows/setup-venv

      - name: Install pytorch
        run: |
          pip install -U --cache-dir $TORCH_CACHE torch torchvision --index-url https://download.pytorch.org/whl/cu121
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"

      - name: Install transformers
        run: |
          git clone https://github.com/huggingface/transformers
          cd transformers
          # if needed switch to the last known good SHA until transformers@master is fixed
          # git checkout 6c3f168b3
          git rev-parse --short HEAD
          pip install .

      - name: Install deepspeed
        run: |
          pip install .[dev,1bit,1bit-mpi,autotuning]
          ds_report

      - name: Python environment
        run: |
          pip list

      - name: Unit tests
        run: |
          unset TORCH_CUDA_ARCH_LIST # only jit compile for current arch
          cd tests
          TEST_LOG_FILE="/tmp/test_log_${GITHUB_RUN_ID}.log"
          echo "Running tests and logging to ${TEST_LOG_FILE}"
          # Let this line return true so that we can grep for "Failed" in the log file
          set +e
          pytest -s unit/comm/test_dist.py::TestDistInferenceAllReduce
          NCCL_SOCKET_IFNAME="" DS_UNITTEST_FILE_STORE_DIR=/dev/shm RUNNING_TEST_LOG_FILE=${TEST_LOG_FILE} pytest $PYTEST_OPTS --forked -n 4 unit/ --torch_ver="2.5" --cuda_ver="12.1"
          PYTEST_EXIT_CODE=$?
          if [ $PYTEST_EXIT_CODE -ne 0 ]; then
            # We don't clean the file here for debugging
            echo "pytest failed with exit code $PYTEST_EXIT_CODE"
            exit $PYTEST_EXIT_CODE
          fi
          grep "Failed" ${TEST_LOG_FILE}
          rm -f ${TEST_LOG_FILE}
          # Do the same as above
          DS_UNITTEST_FILE_STORE_DIR=/dev/shm RUNNING_TEST_LOG_FILE=${TEST_LOG_FILE} pytest $PYTEST_OPTS --forked -m 'sequential' unit/ --torch_ver="2.5" --cuda_ver="12.1"
          PYTEST_EXIT_CODE=$?
          grep "Failed" ${TEST_LOG_FILE}
          if [ $PYTEST_EXIT_CODE -ne 0 ]; then
            echo "pytest failed with exit code $PYTEST_EXIT_CODE"
            exit $PYTEST_EXIT_CODE
          fi
          rm -f ${TEST_LOG_FILE}
