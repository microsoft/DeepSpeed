name: unit-tests

on:
  push:
    branches:
      - 'master'
      - 'staging**'
    paths-ignore:
      - 'docs/**'
  pull_request:
    paths-ignore:
      - 'docs/**'

jobs:
  # unit tests running on nvidia gpus
  nv-torch12-p40:
    runs-on: [self-hosted, nvidia, torch12, p40]

    steps:
      - uses: actions/checkout@v2

      - name: environment
        run: |
          nvidia-smi
          which python
          python --version
          which nvcc
          nvcc --version
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"

      - name: Install deepspeed
        run: |
          pip install .[dev,autotuning]
          ds_report

      - name: Unit tests
        run: |
          if [[ -d ./torch-extensions ]]; then rm -rf ./torch-extensions; fi
          cd tests
          TORCH_EXTENSIONS_DIR=./torch-extensions pytest --color=yes --durations=0 --forked --verbose -n 4 unit/

  nv-torch18-v100:
    runs-on: [self-hosted, nvidia, torch18, v100]

    steps:
      - uses: actions/checkout@v2

      - name: environment
        run: |
          nvidia-smi
          which python
          python --version
          which nvcc
          nvcc --version
          pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
      - name: Install deepspeed
        run: |
          pip install .[dev,1bit,autotuning,sparse_attn]
          ds_report
      - name: Unit tests
        run: |
          unset TORCH_CUDA_ARCH_LIST # only jit compile for current arch
          if [[ -d ./torch-extensions ]]; then rm -rf ./torch-extensions; fi
          cd tests
          TORCH_EXTENSIONS_DIR=./torch-extensions pytest --color=yes --durations=0 --forked --verbose -n 4 -m 'not sequential' unit/
          TORCH_EXTENSIONS_DIR=./torch-extensions pytest --color=yes --durations=0 --forked --verbose -m 'sequential' unit/

  nv-transformers-v100:
    runs-on: [self-hosted, nvidia, torch18, v100]

    steps:
      - uses: actions/checkout@v2

      - name: environment
        run: |
          nvidia-smi
          which python
          python --version
          which nvcc
          nvcc --version
          pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
      - name: Install deepspeed
        run: |
          pip install .[dev,autotuning]
          ds_report
      - name: HF transformers tests
        run: |
          if [[ -d ./torch-extensions ]]; then rm -rf ./torch-extensions; fi
          git clone https://github.com/huggingface/transformers
          cd transformers
          # if needed switch to the last known good SHA until transformers@master is fixed
          # git checkout 1cc453d33
          git rev-parse --short HEAD
          # scipy/sklearn required for tests, using the 'dev' extra forces torch re-install
          pip install .[testing]
          # find reqs used in ds integration tests
          find examples/pytorch  -regextype posix-egrep -regex '.*(language-modeling|question-answering|summarization|image-classification|text-classification|translation).*/requirements.txt' -exec pip install -r {} \;
          TORCH_EXTENSIONS_DIR=./torch-extensions RUN_SLOW=1 pytest --color=yes --durations=0 --verbose tests/deepspeed

  # unit tests running on amd gpus
  amd:
    # The type of runner that the job will run on
    runs-on: [self-hosted, amd]

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: environment
        run: |
          rocm-smi --showhw
          which python
          python --version
          which hipcc
          hipcc --version
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
          sudo apt-get update
          sudo apt-get install -y libaio-dev
      # Runs a set of commands using the runners shell
      - name: Install deepspeed
        run: |
          sudo /opt/conda/bin/pip install .[dev,1bit,autotuning]
          #python -c "from deepspeed.env_report import cli_main; cli_main()"
          ds_report
      # Runs a set of commands using the runners shell
      - name: Unit tests
        run: |
          if [[ -d ./torch-extensions ]]; then rm -rf ./torch-extensions; fi
          cd tests
          TORCH_EXTENSIONS_DIR=./torch-extensions pytest --color=yes --durations=0 --forked --verbose -x -n 4 -m 'not sequential' unit/
          TORCH_EXTENSIONS_DIR=./torch-extensions pytest --color=yes --durations=0 --forked --verbose -x -m 'sequential' unit/

  nv-lightning-v100:
    runs-on: [self-hosted, nvidia, torch18, v100]

    steps:
      - uses: actions/checkout@v2

      - name: environment
        run: |
          nvidia-smi
          which python
          python --version
          which nvcc
          nvcc --version
          pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
      - name: Install deepspeed
        run: |
          pip install .[dev,autotuning]
          ds_report
      - name: PyTorch Lightning Tests
        run: |
          if [[ -d ./torch-extensions ]]; then rm -rf ./torch-extensions; fi
          pip install pytorch-lightning
          cd tests
          TORCH_EXTENSIONS_DIR=./torch-extensions pytest --color=yes --durations=0 --verbose lightning/
